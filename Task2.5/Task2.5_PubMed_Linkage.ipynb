{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.5: PubMed Linkage Pipeline\n",
    "## NCT ID - PubMed Publication Mapping with AI Reference Detection\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "Link clinical trials (NCT IDs) to their associated PubMed publications and identify AI references.\n",
    "\n",
    "### Implementation Details\n",
    "- **Input**: `Task2/clinical_trial_sample (1).csv` (9,428 NCT IDs)\n",
    "- **Sample**: First 100 NCT IDs (scalable to full dataset)\n",
    "- **AI Detection Method**: Rule-Based Keyword Matching (Option 1)\n",
    "- **Output Format**: One row per NCT-PMID pair (Option A)\n",
    "- **API**: NCBI E-utilities (ESearch, ESummary, EFetch)\n",
    "\n",
    "### Output Schema\n",
    "```\n",
    "nct_id, pmid_from_pubmed_search, publication_year, journal, ai_reference_indicator\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "from urllib.parse import quote\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nAPI_KEY = '03780e250434b347f670b6995eaa0d524508'\nBASE_URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/'\nRATE_LIMIT_DELAY = 0.11  # 10 requests/second with API key (0.1s + buffer)\nMAX_RETRIES = 3\nRETRY_DELAY = 2  # seconds\nCHECKPOINT_INTERVAL = 50  # Save progress every 50 NCT IDs\n\n# File paths\nINPUT_FILE = '../Task2/clinical_trial_sample (1).csv'\nOUTPUT_FILE = 'nct_pubmed_linkage.csv'\nCHECKPOINT_FILE = 'checkpoint_results.csv'\n\n# Sample size (set to None to process all)\nSAMPLE_SIZE = None  # Processing all 9,428 NCT IDs"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AI Keyword Dictionary\n",
    "\n",
    "Comprehensive list of AI-related terms for keyword matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total AI keywords: 54\n"
     ]
    }
   ],
   "source": [
    "# AI Keywords for detection\n",
    "AI_KEYWORDS = [\n",
    "    # Core AI Terms\n",
    "    'artificial intelligence', 'machine learning', 'deep learning',\n",
    "    'neural network', 'convolutional neural network', 'cnn',\n",
    "    'recurrent neural network', 'rnn', 'transformer',\n",
    "    \n",
    "    # AI Techniques\n",
    "    'random forest', 'support vector machine', 'svm',\n",
    "    'gradient boosting', 'xgboost', 'decision tree',\n",
    "    'k-nearest neighbor', 'knn', 'naive bayes',\n",
    "    'ensemble learning', 'supervised learning', 'unsupervised learning',\n",
    "    'reinforcement learning', 'transfer learning',\n",
    "    \n",
    "    # Deep Learning Architectures\n",
    "    'lstm', 'gru', 'attention mechanism', 'bert', 'gpt',\n",
    "    'resnet', 'u-net', 'gan', 'generative adversarial network',\n",
    "    'autoencoder', 'variational autoencoder', 'vae',\n",
    "    \n",
    "    # AI Applications in Healthcare/Drug Development\n",
    "    'computer vision', 'natural language processing', 'nlp',\n",
    "    'image recognition', 'object detection', 'semantic segmentation',\n",
    "    'drug discovery ai', 'ai-driven', 'ai-powered', 'ai-enabled',\n",
    "    'predictive modeling', 'feature extraction', 'dimensionality reduction',\n",
    "    \n",
    "    # Specific Algorithms\n",
    "    'logistic regression', 'linear regression', 'pca',\n",
    "    'clustering', 'classification algorithm', 'regression model'\n",
    "]\n",
    "\n",
    "print(f\"Total AI keywords: {len(AI_KEYWORDS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core API Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ESearch - Search for Publications by NCT ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pubmed_by_nct(nct_id: str, api_key: str = API_KEY) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search PubMed for publications referencing a specific NCT ID.\n",
    "    \n",
    "    Args:\n",
    "        nct_id: Clinical trial identifier (e.g., 'NCT00175851')\n",
    "        api_key: NCBI API key for rate limit increase\n",
    "    \n",
    "    Returns:\n",
    "        List of PubMed IDs (PMIDs) as strings\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}esearch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': nct_id,\n",
    "        'retmode': 'json',\n",
    "        'retmax': 100,\n",
    "        'api_key': api_key\n",
    "    }\n",
    "    \n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            pmids = data.get('esearchresult', {}).get('idlist', [])\n",
    "            \n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "            return pmids\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ESearch attempt {attempt + 1} failed for {nct_id}: {e}\")\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(RETRY_DELAY * (attempt + 1))\n",
    "            else:\n",
    "                logger.error(f\"ESearch failed for {nct_id} after {MAX_RETRIES} attempts\")\n",
    "                return []\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ESummary - Retrieve Publication Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_metadata(pmids: List[str], api_key: str = API_KEY) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Retrieve publication metadata (year, journal, title) for a list of PMIDs.\n",
    "    \n",
    "    Args:\n",
    "        pmids: List of PubMed IDs\n",
    "        api_key: NCBI API key\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping PMID to metadata dict with keys:\n",
    "        - 'year': Publication year\n",
    "        - 'journal': Journal name\n",
    "        - 'title': Article title\n",
    "    \"\"\"\n",
    "    if not pmids:\n",
    "        return {}\n",
    "    \n",
    "    url = f\"{BASE_URL}esummary.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': ','.join(pmids),\n",
    "        'retmode': 'json',\n",
    "        'api_key': api_key\n",
    "    }\n",
    "    \n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            result = data.get('result', {})\n",
    "            \n",
    "            metadata = {}\n",
    "            for pmid in pmids:\n",
    "                if pmid in result:\n",
    "                    pub_data = result[pmid]\n",
    "                    \n",
    "                    # Extract year from pubdate\n",
    "                    pubdate = pub_data.get('pubdate', '')\n",
    "                    year = pubdate.split()[0] if pubdate else ''\n",
    "                    \n",
    "                    metadata[pmid] = {\n",
    "                        'year': year,\n",
    "                        'journal': pub_data.get('source', ''),\n",
    "                        'title': pub_data.get('title', '')\n",
    "                    }\n",
    "            \n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "            return metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ESummary attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(RETRY_DELAY * (attempt + 1))\n",
    "            else:\n",
    "                logger.error(f\"ESummary failed after {MAX_RETRIES} attempts\")\n",
    "                return {}\n",
    "    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 EFetch - Retrieve Publication Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_abstracts(pmids: List[str], api_key: str = API_KEY) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Retrieve abstracts for a list of PMIDs.\n",
    "    \n",
    "    Args:\n",
    "        pmids: List of PubMed IDs\n",
    "        api_key: NCBI API key\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping PMID to abstract text\n",
    "    \"\"\"\n",
    "    if not pmids:\n",
    "        return {}\n",
    "    \n",
    "    url = f\"{BASE_URL}efetch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': ','.join(pmids),\n",
    "        'retmode': 'xml',\n",
    "        'rettype': 'abstract',\n",
    "        'api_key': api_key\n",
    "    }\n",
    "    \n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse XML response\n",
    "            root = ET.fromstring(response.content)\n",
    "            \n",
    "            abstracts = {}\n",
    "            for article in root.findall('.//PubmedArticle'):\n",
    "                # Get PMID\n",
    "                pmid_elem = article.find('.//PMID')\n",
    "                if pmid_elem is not None:\n",
    "                    pmid = pmid_elem.text\n",
    "                    \n",
    "                    # Get abstract text\n",
    "                    abstract_texts = []\n",
    "                    for abstract_elem in article.findall('.//AbstractText'):\n",
    "                        if abstract_elem.text:\n",
    "                            abstract_texts.append(abstract_elem.text)\n",
    "                    \n",
    "                    abstracts[pmid] = ' '.join(abstract_texts) if abstract_texts else ''\n",
    "            \n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "            return abstracts\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"EFetch attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(RETRY_DELAY * (attempt + 1))\n",
    "            else:\n",
    "                logger.error(f\"EFetch failed after {MAX_RETRIES} attempts\")\n",
    "                return {}\n",
    "    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AI Reference Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ai_reference(title: str, abstract: str, keywords: List[str] = AI_KEYWORDS) -> bool:\n",
    "    \"\"\"\n",
    "    Detect AI references in publication title and abstract using keyword matching.\n",
    "    \n",
    "    Args:\n",
    "        title: Publication title\n",
    "        abstract: Publication abstract\n",
    "        keywords: List of AI-related keywords to search for\n",
    "    \n",
    "    Returns:\n",
    "        True if any AI keyword is found, False otherwise\n",
    "    \"\"\"\n",
    "    # Combine title and abstract, convert to lowercase\n",
    "    combined_text = (str(title) + ' ' + str(abstract)).lower()\n",
    "    \n",
    "    # Check for keyword matches\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in combined_text:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nct_id(nct_id: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process a single NCT ID: search PubMed, retrieve metadata and abstracts,\n",
    "    detect AI references.\n",
    "    \n",
    "    Args:\n",
    "        nct_id: Clinical trial identifier\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries, one per publication found (or one empty dict if none)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Step 1: Search for PMIDs\n",
    "    pmids = search_pubmed_by_nct(nct_id)\n",
    "    \n",
    "    if not pmids:\n",
    "        # No publications found - return row with empty values\n",
    "        results.append({\n",
    "            'nct_id': nct_id,\n",
    "            'pmid_from_pubmed_search': '',\n",
    "            'publication_year': '',\n",
    "            'journal': '',\n",
    "            'ai_reference_indicator': ''\n",
    "        })\n",
    "        return results\n",
    "    \n",
    "    # Step 2: Get metadata (year, journal, title)\n",
    "    metadata = get_publication_metadata(pmids)\n",
    "    \n",
    "    # Step 3: Get abstracts\n",
    "    abstracts = get_publication_abstracts(pmids)\n",
    "    \n",
    "    # Step 4: Process each publication\n",
    "    for pmid in pmids:\n",
    "        meta = metadata.get(pmid, {})\n",
    "        abstract = abstracts.get(pmid, '')\n",
    "        title = meta.get('title', '')\n",
    "        \n",
    "        # Detect AI reference\n",
    "        ai_detected = detect_ai_reference(title, abstract)\n",
    "        \n",
    "        results.append({\n",
    "            'nct_id': nct_id,\n",
    "            'pmid_from_pubmed_search': pmid,\n",
    "            'publication_year': meta.get('year', ''),\n",
    "            'journal': meta.get('journal', ''),\n",
    "            'ai_reference_indicator': ai_detected\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nct_batch(nct_ids: List[str], checkpoint_file: str = CHECKPOINT_FILE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process a batch of NCT IDs with checkpoint saving.\n",
    "    \n",
    "    Args:\n",
    "        nct_ids: List of NCT IDs to process\n",
    "        checkpoint_file: File path for saving checkpoints\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all results\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Check if checkpoint exists\n",
    "    start_idx = 0\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        logger.info(f\"Loading checkpoint from {checkpoint_file}\")\n",
    "        checkpoint_df = pd.read_csv(checkpoint_file)\n",
    "        all_results = checkpoint_df.to_dict('records')\n",
    "        \n",
    "        # Find where to resume\n",
    "        processed_nct_ids = set(checkpoint_df['nct_id'].unique())\n",
    "        for i, nct_id in enumerate(nct_ids):\n",
    "            if nct_id not in processed_nct_ids:\n",
    "                start_idx = i\n",
    "                break\n",
    "        else:\n",
    "            start_idx = len(nct_ids)  # All processed\n",
    "        \n",
    "        logger.info(f\"Resuming from NCT ID index {start_idx}\")\n",
    "    \n",
    "    # Process NCT IDs\n",
    "    for i, nct_id in enumerate(tqdm(nct_ids[start_idx:], desc=\"Processing NCT IDs\", initial=start_idx, total=len(nct_ids))):\n",
    "        try:\n",
    "            results = process_nct_id(nct_id)\n",
    "            all_results.extend(results)\n",
    "            \n",
    "            # Save checkpoint every CHECKPOINT_INTERVAL\n",
    "            if (start_idx + i + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "                checkpoint_df = pd.DataFrame(all_results)\n",
    "                checkpoint_df.to_csv(checkpoint_file, index=False)\n",
    "                logger.info(f\"Checkpoint saved at NCT ID {start_idx + i + 1}/{len(nct_ids)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {nct_id}: {e}\")\n",
    "            # Add error row\n",
    "            all_results.append({\n",
    "                'nct_id': nct_id,\n",
    "                'pmid_from_pubmed_search': '',\n",
    "                'publication_year': '',\n",
    "                'journal': '',\n",
    "                'ai_reference_indicator': ''\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save final checkpoint\n",
    "    df.to_csv(checkpoint_file, index=False)\n",
    "    logger.info(\"Final checkpoint saved\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NCT IDs in dataset: 9428\n",
      "\n",
      "Dataset columns: ['nct_id', 'brief_title', 'overall_status', 'sponsor_name', 'gvkey_sponsor', 'phase_number', 'start_date', 'start_year']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>sponsor_name</th>\n",
       "      <th>gvkey_sponsor</th>\n",
       "      <th>phase_number</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00175851</td>\n",
       "      <td>Open Label Trial to Study the Long-term Safety...</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>UCB Pharma</td>\n",
       "      <td>24454</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00359632</td>\n",
       "      <td>Study to Evaluate Eye Function in Patients Tak...</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>Pfizer</td>\n",
       "      <td>8530</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-11-01</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00415155</td>\n",
       "      <td>A Study of LY2181308 in Patients With Advanced...</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>Eli Lilly and Company</td>\n",
       "      <td>6730</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-08-01</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00422110</td>\n",
       "      <td>A Study to Evaluate the Efficacy and Safety of...</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>UCB Pharma</td>\n",
       "      <td>24454</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00422422</td>\n",
       "      <td>Open-label, Pharmacokinetic, Safety and Effica...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>UCB Pharma</td>\n",
       "      <td>24454</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nct_id                                        brief_title  \\\n",
       "0  NCT00175851  Open Label Trial to Study the Long-term Safety...   \n",
       "1  NCT00359632  Study to Evaluate Eye Function in Patients Tak...   \n",
       "2  NCT00415155  A Study of LY2181308 in Patients With Advanced...   \n",
       "3  NCT00422110  A Study to Evaluate the Efficacy and Safety of...   \n",
       "4  NCT00422422  Open-label, Pharmacokinetic, Safety and Effica...   \n",
       "\n",
       "  overall_status           sponsor_name  gvkey_sponsor  phase_number  \\\n",
       "0      Withdrawn             UCB Pharma          24454             3   \n",
       "1     Terminated                 Pfizer           8530             3   \n",
       "2      Withdrawn  Eli Lilly and Company           6730             2   \n",
       "3      Withdrawn             UCB Pharma          24454             3   \n",
       "4      Completed             UCB Pharma          24454             2   \n",
       "\n",
       "   start_date  start_year  \n",
       "0  2008-05-01        2008  \n",
       "1  2008-11-01        2008  \n",
       "2  2008-08-01        2008  \n",
       "3  2008-05-01        2008  \n",
       "4  2011-07-01        2011  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load clinical trial dataset\n",
    "df_clinical_trials = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "print(f\"Total NCT IDs in dataset: {len(df_clinical_trials)}\")\n",
    "print(f\"\\nDataset columns: {df_clinical_trials.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_clinical_trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing first 100 NCT IDs (sample mode)\n",
      "\n",
      "Example NCT IDs: ['NCT00175851', 'NCT00359632', 'NCT00415155', 'NCT00422110', 'NCT00422422']\n"
     ]
    }
   ],
   "source": [
    "# Extract NCT IDs (first 100 for sample)\n",
    "if SAMPLE_SIZE is not None:\n",
    "    nct_ids = df_clinical_trials['nct_id'].head(SAMPLE_SIZE).tolist()\n",
    "    print(f\"Processing first {SAMPLE_SIZE} NCT IDs (sample mode)\")\n",
    "else:\n",
    "    nct_ids = df_clinical_trials['nct_id'].tolist()\n",
    "    print(f\"Processing all {len(nct_ids)} NCT IDs (full dataset mode)\")\n",
    "\n",
    "print(f\"\\nExample NCT IDs: {nct_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-15 13:24:07,248 - INFO - Starting PubMed linkage pipeline...\n",
      "Processing NCT IDs:  49%|████▉     | 49/100 [00:46<00:39,  1.28it/s]2026-02-15 13:24:54,717 - INFO - Checkpoint saved at NCT ID 50/100\n",
      "Processing NCT IDs:  99%|█████████▉| 99/100 [01:41<00:01,  1.05s/it]2026-02-15 13:25:49,277 - INFO - Checkpoint saved at NCT ID 100/100\n",
      "Processing NCT IDs: 100%|██████████| 100/100 [01:42<00:00,  1.02s/it]\n",
      "2026-02-15 13:25:49,280 - INFO - Final checkpoint saved\n",
      "2026-02-15 13:25:49,280 - INFO - Pipeline completed!\n"
     ]
    }
   ],
   "source": [
    "# Process all NCT IDs\n",
    "logger.info(\"Starting PubMed linkage pipeline...\")\n",
    "df_results = process_nct_batch(nct_ids)\n",
    "logger.info(\"Pipeline completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to nct_pubmed_linkage.csv\n",
      "\n",
      "Total rows in output: 129\n"
     ]
    }
   ],
   "source": [
    "# Save final results\n",
    "df_results.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Results saved to {OUTPUT_FILE}\")\n",
    "print(f\"\\nTotal rows in output: {len(df_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "1. Total NCT IDs processed: 100\n",
      "2. NCT IDs with at least one publication: 37 (37.0%)\n",
      "3. NCT IDs without publications: 63 (63.0%)\n",
      "\n",
      "4. Total publications found: 66\n",
      "5. Average publications per NCT ID (with pubs): 1.78\n",
      "\n",
      "6. Publications with AI references: 6 (9.1%)\n",
      "7. NCT IDs with at least one AI publication: 6 (6.0%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Total NCT IDs processed\n",
    "total_nct_ids = df_results['nct_id'].nunique()\n",
    "print(f\"\\n1. Total NCT IDs processed: {total_nct_ids}\")\n",
    "\n",
    "# NCT IDs with publications\n",
    "nct_with_pubs = df_results[df_results['pmid_from_pubmed_search'] != '']['nct_id'].nunique()\n",
    "print(f\"2. NCT IDs with at least one publication: {nct_with_pubs} ({nct_with_pubs/total_nct_ids*100:.1f}%)\")\n",
    "\n",
    "# NCT IDs without publications\n",
    "nct_without_pubs = total_nct_ids - nct_with_pubs\n",
    "print(f\"3. NCT IDs without publications: {nct_without_pubs} ({nct_without_pubs/total_nct_ids*100:.1f}%)\")\n",
    "\n",
    "# Total publications found\n",
    "total_publications = df_results[df_results['pmid_from_pubmed_search'] != ''].shape[0]\n",
    "print(f\"\\n4. Total publications found: {total_publications}\")\n",
    "\n",
    "# Average publications per NCT ID (for those with publications)\n",
    "if nct_with_pubs > 0:\n",
    "    avg_pubs = total_publications / nct_with_pubs\n",
    "    print(f\"5. Average publications per NCT ID (with pubs): {avg_pubs:.2f}\")\n",
    "\n",
    "# Publications with AI references\n",
    "ai_publications = df_results[df_results['ai_reference_indicator'] == True].shape[0]\n",
    "if total_publications > 0:\n",
    "    print(f\"\\n6. Publications with AI references: {ai_publications} ({ai_publications/total_publications*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\n6. Publications with AI references: {ai_publications}\")\n",
    "\n",
    "# NCT IDs with at least one AI publication\n",
    "nct_with_ai = df_results[df_results['ai_reference_indicator'] == True]['nct_id'].nunique()\n",
    "print(f\"7. NCT IDs with at least one AI publication: {nct_with_ai} ({nct_with_ai/total_nct_ids*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP 10 JOURNALS\n",
      "============================================================\n",
      "journal\n",
      "Postgrad Med                       4\n",
      "J Child Adolesc Psychopharmacol    4\n",
      "Clin Ther                          2\n",
      "Nat Rev Cancer                     2\n",
      "J Comp Eff Res                     2\n",
      "Cancer                             2\n",
      "Curr Med Res Opin                  2\n",
      "Leuk Lymphoma                      2\n",
      "JAMA Psychiatry                    2\n",
      "J Diabetes Investig                2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Top journals\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 10 JOURNALS\")\n",
    "print(\"=\" * 60)\n",
    "top_journals = df_results[df_results['journal'] != '']['journal'].value_counts().head(10)\n",
    "print(top_journals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PUBLICATION YEAR DISTRIBUTION\n",
      "============================================================\n",
      "publication_year\n",
      "2009    2\n",
      "2010    2\n",
      "2011    8\n",
      "2012    8\n",
      "2013    9\n",
      "2014    7\n",
      "2015    6\n",
      "2016    4\n",
      "2017    7\n",
      "2018    1\n",
      "2019    3\n",
      "2020    3\n",
      "2021    2\n",
      "2023    2\n",
      "2024    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Publication year distribution\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PUBLICATION YEAR DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "year_dist = df_results[df_results['publication_year'] != '']['publication_year'].value_counts().sort_index()\n",
    "print(year_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL OUTPUT PREVIEW\n",
      "============================================================\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>pmid_from_pubmed_search</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>journal</th>\n",
       "      <th>ai_reference_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00175851</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00359632</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00415155</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00422110</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00422422</td>\n",
       "      <td>38518434</td>\n",
       "      <td>2024</td>\n",
       "      <td>Epilepsy Res</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NCT00422422</td>\n",
       "      <td>31810577</td>\n",
       "      <td>2020</td>\n",
       "      <td>Eur J Paediatr Neurol</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NCT00422422</td>\n",
       "      <td>31250322</td>\n",
       "      <td>2019</td>\n",
       "      <td>Paediatr Drugs</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCT00422422</td>\n",
       "      <td>28280887</td>\n",
       "      <td>2017</td>\n",
       "      <td>Eur J Clin Pharmacol</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NCT00436748</td>\n",
       "      <td>36791280</td>\n",
       "      <td>2023</td>\n",
       "      <td>Cochrane Database Syst Rev</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NCT00455052</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nct_id pmid_from_pubmed_search publication_year  \\\n",
       "0  NCT00175851                                            \n",
       "1  NCT00359632                                            \n",
       "2  NCT00415155                                            \n",
       "3  NCT00422110                                            \n",
       "4  NCT00422422                38518434             2024   \n",
       "5  NCT00422422                31810577             2020   \n",
       "6  NCT00422422                31250322             2019   \n",
       "7  NCT00422422                28280887             2017   \n",
       "8  NCT00436748                36791280             2023   \n",
       "9  NCT00455052                                            \n",
       "\n",
       "                      journal ai_reference_indicator  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                Epilepsy Res                  False  \n",
       "5       Eur J Paediatr Neurol                  False  \n",
       "6              Paediatr Drugs                  False  \n",
       "7        Eur J Clin Pharmacol                  False  \n",
       "8  Cochrane Database Syst Rev                   True  \n",
       "9                                                     "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview final output\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL OUTPUT PREVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXAMPLE RESULTS\n",
      "============================================================\n",
      "\n",
      "Example: NCT with publication (No AI reference)\n",
      "     nct_id pmid_from_pubmed_search publication_year      journal ai_reference_indicator\n",
      "NCT00422422                38518434             2024 Epilepsy Res                  False\n",
      "\n",
      "Example: NCT with publication (AI reference detected)\n",
      "     nct_id pmid_from_pubmed_search publication_year                    journal ai_reference_indicator\n",
      "NCT00436748                36791280             2023 Cochrane Database Syst Rev                   True\n",
      "\n",
      "Example: NCT without publications\n",
      "     nct_id pmid_from_pubmed_search publication_year journal ai_reference_indicator\n",
      "NCT00175851                                                                        \n"
     ]
    }
   ],
   "source": [
    "# Show examples of different categories\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example: NCT with publications (no AI)\n",
    "no_ai_example = df_results[(df_results['pmid_from_pubmed_search'] != '') & \n",
    "                           (df_results['ai_reference_indicator'] == False)].head(1)\n",
    "if not no_ai_example.empty:\n",
    "    print(\"\\nExample: NCT with publication (No AI reference)\")\n",
    "    print(no_ai_example.to_string(index=False))\n",
    "\n",
    "# Example: NCT with AI publication\n",
    "ai_example = df_results[df_results['ai_reference_indicator'] == True].head(1)\n",
    "if not ai_example.empty:\n",
    "    print(\"\\nExample: NCT with publication (AI reference detected)\")\n",
    "    print(ai_example.to_string(index=False))\n",
    "\n",
    "# Example: NCT without publications\n",
    "no_pub_example = df_results[df_results['pmid_from_pubmed_search'] == ''].head(1)\n",
    "if not no_pub_example.empty:\n",
    "    print(\"\\nExample: NCT without publications\")\n",
    "    print(no_pub_example.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Notes and Instructions\n",
    "\n",
    "### Scaling to Full Dataset\n",
    "To process all 9,428 NCT IDs instead of just 100:\n",
    "1. Change `SAMPLE_SIZE = 100` to `SAMPLE_SIZE = None` in the Configuration cell\n",
    "2. Re-run all cells from \"6. Load Input Data\" onwards\n",
    "3. The pipeline will automatically use checkpoints to save progress\n",
    "\n",
    "### Checkpoint/Resume Functionality\n",
    "- Progress is automatically saved every 50 NCT IDs\n",
    "- If the notebook crashes or is interrupted, simply re-run the pipeline\n",
    "- It will automatically detect the checkpoint file and resume from where it stopped\n",
    "- Delete `checkpoint_results.csv` to start fresh\n",
    "\n",
    "### API Rate Limits\n",
    "- With API key: 10 requests/second\n",
    "- Estimated time for 100 NCT IDs: ~10-15 minutes\n",
    "- Estimated time for all 9,428 NCT IDs: ~15-20 hours\n",
    "\n",
    "### Output Format\n",
    "- **nct_id**: Clinical trial identifier\n",
    "- **pmid_from_pubmed_search**: PubMed ID (empty if no publications)\n",
    "- **publication_year**: Year of publication (empty if no publications)\n",
    "- **journal**: Journal name (empty if no publications)\n",
    "- **ai_reference_indicator**: True/False/empty (empty if no publications)\n",
    "\n",
    "### Customization\n",
    "- To modify AI keywords, edit the `AI_KEYWORDS` list in Section 2\n",
    "- To adjust checkpoint frequency, change `CHECKPOINT_INTERVAL` in Configuration\n",
    "- To modify rate limits, adjust `RATE_LIMIT_DELAY` in Configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}